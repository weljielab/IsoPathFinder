{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "#This script is designed to read in the list of MetaCyc atom-mapping solutions,\n",
    "#.. and incorporate an isotope tracer (e.g. 13C6 Glucose) to enumerate\n",
    "#.. the possible metabolite fates of the labeled carbons\n",
    "#Inputs - reaction-linksAdd.txt, atom-mappings-smiles-flyAdd.dat, PubChemCpdMatchAdd.csv,  \n",
    "#Outputs - Dictionary_FromRound_[0-9].pkl\n",
    "#\n",
    "#1) All reactions which contain a labeled metabolite are identified\n",
    "#2) The carbons in the product metabolites are labeled for each reaction\n",
    "#3) Those newly labeled product metabolites are added to the compound list\n",
    "#4) The reactants, products, and ECs are built into a dictionary and exported, which can be used to build isotope labeling routes (separate .ipynb)\n",
    "#5) This process is repeated for as many reactions as desired\n",
    "#\n",
    "# Note: since 13C02 is a common product, one can optionally remove CO2\n",
    "#.. at the end of each reaction round - this step will GREATLY reduce the\n",
    "#.. number of labeling possibilities\n",
    "#\n",
    "#This script is built to perform 13C tracing (or any isotope of carbon), however modifications can be made throughout the script to do e.g. 15N or 18O, etc..\n",
    "#\n",
    "#\n",
    "# Important package versions used in this script (some aren't mentioned here, I suspect different versions of e.g. itertools will not have a substantial impact on the script):\n",
    "# numpy: 1.11.3\n",
    "# pandas: 0.19.2\n",
    "# dill: 0.2.5\n",
    "# pathos: 0.2.0\n",
    "# Note this script was executed on an Ubuntu 15.10 Virtual Machine\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, pandas, os, sys, re, itertools, csv\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import dill as pickle\n",
    "from pathos.helpers import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the reaction links of RXNs to ECs\n",
    "#Note some reactions were manually added, thus an adapted MetaCyc file 'reaction-links.dat' is used here\n",
    "MetaCycReactionLinks=pandas.read_csv('reaction-linksAdd.txt',sep='\\t',skiprows=1)\n",
    "MetaCycReactionLinks=MetaCycReactionLinks.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trim reaction links\n",
    "MetaCycReactionLinks=MetaCycReactionLinks[MetaCycReactionLinks.columns[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "MetaCycReactionLinks.columns=['MetaCyc','EC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix some naming errors\n",
    "MetaCycReactionLinks.MetaCyc=[re.sub('\\?','+-RXN',x) for x in MetaCycReactionLinks.MetaCyc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#Note! Some ECs are manually removed 'ahead of time'\n",
    "#These include Rubisco or bacterial enzymes, and can\n",
    "#... be modified by the user\n",
    "####################################################\n",
    "\n",
    "###Change this list to your preference\n",
    "ECDrop=['EC-4.1.2.22','EC-4.1.1.39']\n",
    "###\n",
    "\n",
    "MetaCycReactionLinks=MetaCycReactionLinks[~MetaCycReactionLinks['EC'].isin(ECDrop)]\n",
    "MetaCycReactionLinks=MetaCycReactionLinks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of MetaCyc RXN IDs with EC numbers as values\n",
    "MetaCycReactionLinksDict=dict(zip(MetaCycReactionLinks.MetaCyc,MetaCycReactionLinks.EC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the Smiles Matrix of reactions to compounds\n",
    "#Note some mappings were added manually here\n",
    "#If you want to read all MetaCyc reactions, use atom-mappings-smilesAdd.dat, or -mouseAdd or flyAdd for other organisms\n",
    "#SmilesMap=pandas.read_csv('atom-mappings-smiles-humanAdd.dat',sep='\\t',skiprows=1,header=None,usecols=[0,1])\n",
    "SmilesMap=pandas.read_csv('atom-mappings-smiles-flyAdd.dat',sep='\\t',skiprows=1,header=None,usecols=[0,1])\n",
    "SmilesMap.columns=['Reaction','Compounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the SmilesMap based on the KEGG EC match\n",
    "SmilesMap=SmilesMap[SmilesMap['Reaction'].isin(MetaCycReactionLinks.MetaCyc)]\n",
    "SmilesMap=SmilesMap.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in list of Smiles->'English' conversions\n",
    "#This list is derived from the pubchempy python module\n",
    "PubChemCpds=pandas.read_csv('PubChemCpdMatchAdd.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compiled expression matches - may shave some time off later given the number of string matches I perform\n",
    "SmilesStringRe1=re.compile(r':\\d?\\d]*')\n",
    "SmilesStringRe2=re.compile(r'\\[|\\]')\n",
    "SmilesStringRe3=re.compile(r'^\\'|\\'$')\n",
    "MetaCycSplitter=re.compile(r'(>>|\\.)')\n",
    "CarbFinder=re.compile(r'C\\*?')\n",
    "LabelFinder=re.compile(r'C\\*:\\d+')\n",
    "SpaceRemover=re.compile(r'^ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to pull out 'English name' from the Smiles format\n",
    "PubChemCpdsDict=dict(zip(PubChemCpds.Smiles,PubChemCpds.Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get a smiles string from the MetaCyc-specific Smiles annotation\n",
    "#Using compiled expressions\n",
    "def SmilesFromMetaCycCpd(OneCpdString):\n",
    "    \n",
    "    #Get rid of the bracketing\n",
    "    OneCpdString=SmilesStringRe1.sub(repl='',string=OneCpdString)\n",
    "    \n",
    "    OneCpdString=SmilesStringRe2.sub(repl='',string=OneCpdString)\n",
    "    \n",
    "    #remove extra apostrophes if they exist\n",
    "    if OneCpdString.startswith('\\'') and OneCpdString.endswith('\\''):\n",
    "        OneCpdString=SmilesStringRe3.sub(repl='',string=OneCpdString)\n",
    "        \n",
    "    return(OneCpdString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#Define the isotope tracer of interest here!\n",
    "\n",
    "#If you need help finding the right SMILES for your input tracer of interest\n",
    "#... check the PubChemCpds list\n",
    "############################################################################\n",
    "\n",
    "#Pulling any hexopyranose from PubChem\n",
    "GLUCOSESMILES=['C(O)C1(C(O)C(O)C(O)C(O)O1)','C(C1(C(C(C(C(O1)O)O)O)O))O',\n",
    "              'C(O)C1(OC(C(C(C1O)O)O)O)','C(C1(OC(C(C(C1O)O)O)O))O',\n",
    "              'C(O)C1(OC(O)C(O)C(O)C(O)1)','C(C1(C(O)C(O)C(O)C(O)O1))O']\n",
    "\n",
    "#Defining the initial list of labeled compounds - this list will seed the 1st round of metabolic reactions\n",
    "LabListInitial=['C*(O)C*1(C*(O)C*(O)C*(O)C*(O)O1)','C*(C*1(C*(C*(C*(C*(O1)O)O)O)O))O',\n",
    "              'C*(O)C*1(OC*(C*(C*(C*1O)O)O)O)','C*(C*1(OC*(C*(C*(C*1O)O)O)O))O',\n",
    "              'C*(O)C*1(OC*(O)C*(O)C*(O)C*(O)1)','C*(C*1(C*(O)C*(O)C*(O)C*(O)O1))O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionary of MetaCyc Rxn to MetaCyc Compound list split up\n",
    "SmilesMapDict=dict(zip(SmilesMap.Reaction,SmilesMap.Compounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of MetaCyc Rxn to Compound items in SMILES format\n",
    "SmilesMapSmilesSplit=SmilesMap.Compounds.str.split('[.]|[>>]')\n",
    "Reducer=lambda x:[SmilesFromMetaCycCpd(y) for y in x]\n",
    "SmilesMapSmilesSplit=SmilesMapSmilesSplit.apply(Reducer)\n",
    "SmilesMapSmilesCpdDict=dict(zip(SmilesMap.Reaction,SmilesMapSmilesSplit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master compound list built from SmilesMap\n",
    "MasterCpdList=list(chain.from_iterable(SmilesMapSmilesSplit))\n",
    "MasterCpdList=list(set(MasterCpdList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Master dictionary of the reactions which contain any one of the 12k compounds - useful for GenerateNewReaction function\n",
    "CpdToRxnDict={}\n",
    "for cpd in range(len(MasterCpdList)):\n",
    "    xlist=[k for (k,v) in SmilesMapSmilesCpdDict.items() if MasterCpdList[cpd] in v] #56s for cpd list of 12k\n",
    "    CpdToRxnDict.setdefault(MasterCpdList[cpd],[])\n",
    "    CpdToRxnDict[MasterCpdList[cpd]].extend(xlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the index in a reaction that is already split by its .'s and >>'s of the >> (i.e. what splits the reactants and products)\n",
    "def GetTheReactantsLength(OneSplitSMILESReaction):\n",
    "    for i in range(0,len(OneSplitSMILESReaction)):\n",
    "        if len(OneSplitSMILESReaction[i])==0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionary of the point of equilibration sign based on str.split('[.]|[>>]'), with keys as the MetaCyc RXN IDs\n",
    "ReactantLengthDict=dict(zip(SmilesMap.Reaction,SmilesMapSmilesSplit.apply(GetTheReactantsLength)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Insert a labeled compound into a MetaCyc reaction by finding its isotope-stripped version\n",
    "def InsertLabeledMetabIntoString(BigString,LabMetab,StripMetab):\n",
    "    \n",
    "    #Find the carbons\n",
    "    Carbs=CarbFinder.findall(LabMetab)\n",
    "    \n",
    "    #Iterative list of the carbon locations with a label\n",
    "    match=[j for j in range(len(Carbs)) if Carbs[j].__contains__('C*')]\n",
    "\n",
    "    #Split the MetaCyc reaction compound string into reactants and products\n",
    "    TempRxn=MetaCycSplitter.split(str(BigString))\n",
    "    \n",
    "    #Convert each item to Smiles format\n",
    "    TempRxn1=[SmilesFromMetaCycCpd(x) for x in TempRxn]\n",
    "    \n",
    "    for metab in range(len(TempRxn)):\n",
    "        \n",
    "        #Find the carbon locations\n",
    "        CIndicies=[m.start() for m in re.finditer('C',TempRxn[metab])]\n",
    "        \n",
    "        #Listify\n",
    "        ListMetab=list(TempRxn[metab])\n",
    "        \n",
    "        #If any of the items from the MetaCyc reactants/products list match the metabolite which contains the isotope..\n",
    "        if TempRxn1[metab]==StripMetab:\n",
    "            \n",
    "            for location in range(len(match)):\n",
    "                \n",
    "                #Insert the isotope at the right location\n",
    "                ListMetab[CIndicies[match[location]]]='C*'\n",
    "                \n",
    "                #Rejoin the list\n",
    "                ConvertedMetab=''.join(ListMetab)\n",
    "                \n",
    "                #Replace old metabolite with newly labeled form\n",
    "                TempRxn[metab]=ConvertedMetab\n",
    "            \n",
    "        #Convert back to MetaCyc format\n",
    "        BigString=''.join(item for item in TempRxn)\n",
    "        \n",
    "    return(BigString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take the list of labeled compounds, and find all the Metacyc reactions that contain the compounds, build a matrix\n",
    "def BuildReactionMatrixFromCpdList(ListOfLabeledCpds):\n",
    "    \n",
    "    MasterRxnList=[]\n",
    "    MasterCompoundList=[]\n",
    "    \n",
    "    #Strip all labeled metabolites of isotopes for matching purposes\n",
    "    StrippedList=[x.replace('C*','C') for x in ListOfLabeledCpds]\n",
    "    \n",
    "    for labcpd,nolabcpd in zip(ListOfLabeledCpds,StrippedList):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            #Try using the dictionary to generate a list of reactions for each given metabolite\n",
    "            RxnList=CpdToRxnDict[nolabcpd]\n",
    "            \n",
    "            #Get the Metacyc compounds from each reaction\n",
    "            RxnCompounds=[SmilesMapDict[x] for x in RxnList]\n",
    "            \n",
    "            #Insert the labeled compound into the Metacyc compounds list\n",
    "            RxnCompounds=[InsertLabeledMetabIntoString(x,labcpd,nolabcpd) for x in RxnCompounds]\n",
    "            \n",
    "        except:\n",
    "            RxnList=[]\n",
    "            RxnCompounds=[]\n",
    "        \n",
    "        #Build out the lists\n",
    "        MasterRxnList.extend(RxnList)\n",
    "        MasterCompoundList.extend(RxnCompounds)\n",
    "\n",
    "    #Turn into Series' for later apply functions and indexing\n",
    "    PrepMatrix=pandas.Series([MasterRxnList,MasterCompoundList])\n",
    "    \n",
    "    #Build DataFrame\n",
    "    PrepMatrix=BuildReactionMatrixExport(PrepMatrix)\n",
    "\n",
    "    return(PrepMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to build the reaction matrix export\n",
    "def BuildReactionMatrixExport(PreLabeledReactionMatrix):\n",
    "    \n",
    "        #Build new data frame with same rows as ReactionMatrix\n",
    "        DataFrameExport=pandas.DataFrame(index=numpy.arange(len(PreLabeledReactionMatrix[0])),columns=['Reaction','Compounds','Reactants','Products'])\n",
    "        \n",
    "        #Fill the reaction column from the lists of reactions and compounds with isotope addition from 'BuildReactionMatrix' function\n",
    "        DataFrameExport['Reaction']=PreLabeledReactionMatrix[0]\n",
    "        DataFrameExport['Compounds']=PreLabeledReactionMatrix[1]\n",
    "        \n",
    "        del PreLabeledReactionMatrix\n",
    "        \n",
    "        return(DataFrameExport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take list of carbon numbers, find them in the metabolite of interest, and replace Cs with C*s (i.e. with isotope)\n",
    "def MiniInsertLabel(CarbonRegexList,Metabolite):\n",
    "    for num in CarbonRegexList:\n",
    "        Metabolite=re.sub(pattern='\\\\b'+'C:'+num+'\\\\b',repl='C*:'+num,string=Metabolite)\n",
    "    return(Metabolite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take labeled reactants, find carbon numbers, map to products and label those carbons\n",
    "def GenericLabelingReactionMatrixApply(UnlabeledReactionMatrix):\n",
    "    \n",
    "    #Split into metabolite items\n",
    "    UnlabeledReactionMatrix=MetaCycSplitter.split(UnlabeledReactionMatrix)\n",
    "    \n",
    "    #Get all reactants with label\n",
    "    ReactantList=[item for item in UnlabeledReactionMatrix if '*' in item]\n",
    "    \n",
    "    #find carbom numbers to get labeled\n",
    "    FindThese=LabelFinder.findall(str(ReactantList))\n",
    "    \n",
    "    #Return only the numbers that are assigned to the carbons\n",
    "    FindThese=[x.replace('C*:','') for x in FindThese]\n",
    "    \n",
    "    #Get cpds not currently labeled\n",
    "    HoldList=[item for item in UnlabeledReactionMatrix if not '*' in item]\n",
    "    \n",
    "    #Return the smiles format of reactants labeled cpds\n",
    "    ReactantList=[SmilesFromMetaCycCpd(x) for x in ReactantList]\n",
    "    \n",
    "    #Label any metabolite that contains a carbon number from FindThese\n",
    "    HoldList=[MiniInsertLabel(FindThese,x) for x in HoldList]\n",
    "    \n",
    "    #Pull out only metabolites which obtained a labeled (i.e. the Products)\n",
    "    ProductList=[item for item in HoldList if '*' in item]\n",
    "    \n",
    "    #Return Smiles\n",
    "    ProductList=[SmilesFromMetaCycCpd(x) for x in ProductList]\n",
    "    \n",
    "    #Build tuple of reactants and products\n",
    "    UnlabeledReactionMatrix=(ReactantList,ProductList)\n",
    "    \n",
    "    del ReactantList,ProductList,HoldList\n",
    "\n",
    "    return(UnlabeledReactionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unpack the tuple of reactants and products, fill in the appropriate columns of the dataframe\n",
    "def UnpackAndFill(ReactedMatrix):\n",
    "    Reactants,Products=zip(*ReactedMatrix.Compounds)\n",
    "    ReactedMatrix.Reactants=Reactants\n",
    "    ReactedMatrix.Products=Products\n",
    "    del Reactants,Products\n",
    "    ReactedMatrix.drop('Compounds',axis=1,inplace=True)\n",
    "    return(ReactedMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#New function, take products from Labeled reaction matrix, make new labeled list\n",
    "def NewLabeledCpdList(ReactedMatrix):\n",
    "    \n",
    "    #Build list of cpds from the products column\n",
    "    NewList=list(chain.from_iterable(ReactedMatrix.NewCpds))\n",
    "\n",
    "    #Some metabolites had additional spaces which messed up the matching\n",
    "    NewList=[re.split(' ',x) for x in NewList]\n",
    "    NewList=list(chain.from_iterable(NewList))\n",
    "    NewList=[x for x in NewList if '*' in x]\n",
    "    \n",
    "    ######################################################\n",
    "    #Important!\n",
    "    #The user can add metabolites (by their smiles format)\n",
    "    #... to remove at each round\n",
    "    #\n",
    "    #Adding too many metabolites here will probably slow\n",
    "    #... the program significantly, fyi..\n",
    "    ######################################################\n",
    "    \n",
    "    #Remove 13CO2 at the end of each round! Otherwise a large number of the reaction possibilities contain a CO2 which is probably not aligned with experimental reality \n",
    "    NewList=[x for x in NewList if re.sub('\\*','',x)!='C(=O)=O']\n",
    "    \n",
    "    #Remove labeled sorboses, doesn't seem to have physiological relevance\n",
    "    NewList=[x for x in NewList if re.sub('\\*','',x)!='C(O)C(=O)C(O)C(O)C(O)CO']\n",
    "    \n",
    "    #Keep unique elements of list\n",
    "    NewList=list(set(NewList))\n",
    "    \n",
    "    return(NewList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use MetaCycReactionLinksDict for reaction conversion from MetaCyc's RXN to EC\n",
    "def ReactionConvert(RunReactionMatrix):\n",
    "    if str(MetaCycReactionLinksDict[RunReactionMatrix])!='nan':\n",
    "        RunReactionMatrix=MetaCycReactionLinksDict[RunReactionMatrix]\n",
    "    return(RunReactionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Name converter from Smiles to 'English'\n",
    "def ReactantConvertOne(x):\n",
    "    try:\n",
    "        x=PubChemCpdsDict[x]\n",
    "    except:\n",
    "        x=''\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert a compound string so that it can be matched to an 'English' name\n",
    "#Compiled patterns\n",
    "ChargeRemover=re.compile(r'\\+|\\-')\n",
    "ExtraPostasRemover=re.compile('^\\'|\\'$')\n",
    "\n",
    "def LabelStrippersOne(x):\n",
    "    \n",
    "    #Remove labels #Not needed when keeping smiles\n",
    "    #x=x.replace('*','')\n",
    "    \n",
    "    #Remove extra Rs? #Not needed when keeping smiles\n",
    "    #x=x.replace('R','')\n",
    "    \n",
    "    #Remove charges\n",
    "    x=ChargeRemover.sub('',string=str(x))\n",
    "    \n",
    "    #Remove any rextra apostrophes\n",
    "    x=ExtraPostasRemover.sub('',string=str(x))\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert a labeled metabolite string into 'English isotopomer name (e.g. Glucose M+6)\n",
    "def CombinedConvertMetabs(OneLabeledMatrixCpd):\n",
    "    \n",
    "    #Get number of label counts # Not needed when keeping smiles\n",
    "    #OneLabeledMatrixCpdCarbs=OneLabeledMatrixCpd.count('*')\n",
    "    \n",
    "    #Strip labels and charges\n",
    "    OneLabeledMatrixCpdsEnglish=LabelStrippersOne(OneLabeledMatrixCpd)\n",
    "    \n",
    "    #Convert to English using metabolite dictionary # Not needed when keeping smiles format\n",
    "    #OneLabeledMatrixCpdsEnglish=ReactantConvertOne(OneLabeledMatrixCpdsEnglish)\n",
    "    \n",
    "    #Format string to use both english name and label number # Not needed when keeping smiles format\n",
    "    #OneLabeledMatrixCpd=str('{0} M+{1}').format(OneLabeledMatrixCpdsEnglish,OneLabeledMatrixCpdCarbs)\n",
    "    \n",
    "    #Changed from return(OneLabeledMatrixCpd) to keep smiles names\n",
    "    return(OneLabeledMatrixCpdsEnglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to call the conversion of reactants and products to english\n",
    "def UpdatedMetabConvert(LabeledMatrixCpds):\n",
    "    LabeledMatrixCpds=[CombinedConvertMetabs(x) for x in LabeledMatrixCpds]\n",
    "    return(LabeledMatrixCpds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trim reaction matrix to drop nonmatching metabolites (i.e. they can't be named)\n",
    "def TrimExportReactionMatrix(ExportReactionMatrix):\n",
    "\n",
    "    #Drop the nans\n",
    "    ExportReactionMatrix=ExportReactionMatrix.dropna(subset=['Reactants'])\n",
    "    ExportReactionMatrix=ExportReactionMatrix.dropna(subset=['Products'])\n",
    "    \n",
    "    #drop row indicies that have a blank Labeled Reactants or Products cell\n",
    "    ExportReactionMatrix=ExportReactionMatrix.drop(ExportReactionMatrix[ExportReactionMatrix['Reactants'].map(len)==0].index,axis=0)\n",
    "    ExportReactionMatrix=ExportReactionMatrix.drop(ExportReactionMatrix[ExportReactionMatrix['Products'].map(len)==0].index,axis=0)\n",
    "\n",
    "    return(ExportReactionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If metabolite didn't get an english name match, drop it\n",
    "def DropMissingMetabs(ConvertedMatrixColumnCpd):\n",
    "\n",
    "    ConvertedMatrixColumnCpd=[item for item in ConvertedMatrixColumnCpd if not re.search('^ M+[0-9]*',item)]\n",
    "\n",
    "    return(ConvertedMatrixColumnCpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert to english, build the dictionary for round 1\n",
    "def ConvertMatrixToEnglish(LabeledReactionMatrix):\n",
    "    \n",
    "    #Convert RXN to EC\n",
    "    LabeledReactionMatrix.Reaction=LabeledReactionMatrix.Reaction.apply(ReactionConvert)\n",
    "   \n",
    "    ##############\n",
    "    #Update - don't convert names, do that at the end of the IsoPathFinder Step, and instead keep the SMILES\n",
    "    #.. format instead\n",
    "    \n",
    "    #Convert reactants and products to english M+x isotopomer names #Added back to include the charge strip\n",
    "    LabeledReactionMatrix.Reactants=LabeledReactionMatrix.Reactants.apply(UpdatedMetabConvert)    \n",
    "    LabeledReactionMatrix.Products=LabeledReactionMatrix.Products.apply(UpdatedMetabConvert)\n",
    "\n",
    "    #Remove unnamed metabolites\n",
    "    ##LabeledReactionMatrix.Reactants=LabeledReactionMatrix.Reactants.apply(DropMissingMetabs) #622ms, 25% faster than before\n",
    "    ##LabeledReactionMatrix.Products=LabeledReactionMatrix.Products.apply(DropMissingMetabs) #622ms, 25% faster than before\n",
    "\n",
    "    #Drop empty fields\n",
    "    ##LabeledReactionMatrix=TrimExportReactionMatrix(LabeledReactionMatrix)\n",
    "    ##LabeledReactionMatrix=LabeledReactionMatrix.reset_index(drop=True)\n",
    "    ############\n",
    "    \n",
    "    return(LabeledReactionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build dictiontary/hashable results from the labeling matrix\n",
    "def MakingDict(LabeledRxnMatrix):\n",
    "    \n",
    "    Dictionary=defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for rxns in range(len(LabeledRxnMatrix)):\n",
    "        \n",
    "        #Remove any extra spaces\n",
    "        Reactants=[SpaceRemover.sub('',x) for x in LabeledRxnMatrix.Reactants[rxns]]\n",
    "\n",
    "        Products=[SpaceRemover.sub('',x) for x in LabeledRxnMatrix.Products[rxns]]\n",
    "        \n",
    "        #Add values to the Product keys, both the reactants as well as the reactants' as keys to the enzymes\n",
    "        if len(Products)==1:\n",
    "            if LabeledRxnMatrix.Reaction[rxns] in Dictionary[str(Products).strip('[]|\\'')][Reactants[0]]:\n",
    "                pass\n",
    "            else:\n",
    "                Dictionary[str(Products).strip('[]|\\'')][Reactants[0]].append(LabeledRxnMatrix.Reaction[rxns])\n",
    "           \n",
    "        if len(Products)>1:\n",
    "            for cpd in range(len(Products)):\n",
    "                if LabeledRxnMatrix.Reaction[rxns] in Dictionary[str(Products[cpd]).strip('[]|\\'')][Reactants[0]]:\n",
    "                    pass\n",
    "                else:\n",
    "                    Dictionary[str(Products[cpd]).strip('[]|\\'')][Reactants[0]].append(LabeledRxnMatrix.Reaction[rxns])\n",
    "\n",
    "    \n",
    "    return(Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What I had found was that for the first couple reaction rounds, the dataframes\n",
    "#.. were generally small and only took a few seconds\n",
    "#.. However, in later rounds I needed to use parallelization (especially true if running with the entire MetaCyc model)\n",
    "#.. which is the code below (with specific parallel functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Done\n",
      "Wall time: 48.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Nonparallel version - round 1\n",
    "NextRoundReaction=BuildReactionMatrixFromCpdList(LabListInitial)\n",
    "NextRoundReaction.Compounds=NextRoundReaction.Compounds.apply(GenericLabelingReactionMatrixApply)\n",
    "NextRoundReaction=UnpackAndFill(NextRoundReaction)\n",
    "NextRoundReaction['NewCpds']=NextRoundReaction.Products\n",
    "NextRoundCpdList=NewLabeledCpdList(NextRoundReaction)\n",
    "NextRoundReaction=ConvertMatrixToEnglish(NextRoundReaction)\n",
    "DictionaryRound=MakingDict(NextRoundReaction)\n",
    "output=open('Dictionary_FromRound_1.pkl','wb', -1) #Change\n",
    "pickle.dump(DictionaryRound,output,protocol=4)\n",
    "print('Round 1 Done') #Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Parallel functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build and run the reaction, also append the new labeled cpd list\n",
    "def PipePandaProcess(CpdList):\n",
    "    \n",
    "    #build reaction matrix\n",
    "    ReactionMatrix=BuildReactionMatrixFromCpdList(CpdList)\n",
    "    \n",
    "    #Run labeling reaction\n",
    "    ReactionMatrix.Compounds=ReactionMatrix.Compounds.apply(GenericLabelingReactionMatrixApply)\n",
    "    \n",
    "    #Prep step\n",
    "    ReactionMatrix=UnpackAndFill(ReactionMatrix)\n",
    "    \n",
    "    #Add new column for labeled list export later\n",
    "    ReactionMatrix['NewCpds']=ReactionMatrix.Products\n",
    "    \n",
    "    #Convert matrix to English\n",
    "    ReactionMatrix=ConvertMatrixToEnglish(ReactionMatrix)\n",
    "        \n",
    "    return(ReactionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Successful write out in parallel function\n",
    "#Note this function will write out a temporary dataframe and read it back in pieces to build the reaction dictionary, which alleviates memory concerns by writing to disk\n",
    "def ParallelRxnBuildWriteOut(LabeledList,BuildFunction,RoundNum):\n",
    "    \n",
    "    #Split into - using 16 cores, break up evenly\n",
    "    SplitList=numpy.array_split(LabeledList,16*32)\n",
    "    \n",
    "    #Fill new list of labeled cpds\n",
    "    NewCpdList=[]\n",
    "    \n",
    "    #Build multiprocessing pool object with 16 processors\n",
    "    pooler=mp.Pool(16)\n",
    "\n",
    "    #Set up the new file\n",
    "    with open('TempPandaDF.csv','w') as fp:\n",
    "        \n",
    "        #For each result in the Build function using an item from SplitList\n",
    "        for result in pooler.imap(BuildFunction,SplitList):\n",
    "            \n",
    "            #Building new cpd list\n",
    "            NewCpds=NewLabeledCpdList(result)\n",
    "            NewCpdList.extend(NewCpds)\n",
    "            \n",
    "            #Each result is a Pandas Object, so write it to csv\n",
    "            result.to_csv(fp,index=False,header=False)\n",
    "\n",
    "    \n",
    "    pooler.close()\n",
    "    pooler.join()\n",
    "\n",
    "    #Unique items\n",
    "    NewCpdList=list(set(NewCpdList))\n",
    "    \n",
    "    #Write File, optional\n",
    "    #CpdFile='LabeledCpds_FromRound_{0}.csv'.format(RoundNum) #Change\n",
    "    #with open(CpdFile,'w') as output:\n",
    "    #    writer=csv.writer(output,lineterminator='\\n')\n",
    "    #    for val in NewCpdList:\n",
    "    #        writer.writerow([val])\n",
    "    \n",
    "    #Return CpdList for next round\n",
    "    return(NewCpdList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Successful write out in parallel function\n",
    "def ParallelRxnBuildWriteOutRd2(LabeledList,BuildFunction,RoundNum):\n",
    "    \n",
    "    #No chunks for round 2\n",
    "    SplitList=numpy.array_split(LabeledList,16)\n",
    "    \n",
    "    #Fill new list of labeled cpds\n",
    "    NewCpdList=[]\n",
    "    \n",
    "    #Build multiprocessing pool object with num of cpus\n",
    "    pooler=mp.Pool(16)\n",
    "\n",
    "    #Set up the new file\n",
    "    with open('TempPandaDF.csv','w') as fp:\n",
    "        \n",
    "        #For each result in the Build function using an item from SplitList\n",
    "        for result in pooler.imap(BuildFunction,SplitList):\n",
    "            \n",
    "            #Building new cpd list\n",
    "            NewCpds=NewLabeledCpdList(result)\n",
    "            NewCpdList.extend(NewCpds)\n",
    "            \n",
    "            #Each result is a Pandas Object, so write it to csv\n",
    "            result.to_csv(fp,index=False,header=False)\n",
    "\n",
    "    \n",
    "    pooler.close()\n",
    "    pooler.join()\n",
    "\n",
    "    #Unique items\n",
    "    NewCpdList=list(set(NewCpdList))\n",
    "    \n",
    "    #Write File, optional\n",
    "    #CpdFile='LabeledCpds_FromRound_{0}.csv'.format(RoundNum) #Change\n",
    "    #with open(CpdFile,'w') as output:\n",
    "    #    writer=csv.writer(output,lineterminator='\\n')\n",
    "    #    for val in NewCpdList:\n",
    "    #        writer.writerow([val])\n",
    "    \n",
    "    #Return CpdList for next round\n",
    "    return(NewCpdList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvertBackForDict(PandaDF):\n",
    "    #Convert back to original pandas formatting\n",
    "    PandaDF.Reactants=PandaDF.Reactants.apply(ConvertBackForDictSub)\n",
    "    PandaDF.Products=PandaDF.Products.apply(ConvertBackForDictSub)\n",
    "    return(PandaDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvertBackForDictSub(PandaDFColumn):\n",
    "    PandaDFColumn=re.sub('\\'|\\[|\\]','',PandaDFColumn)\n",
    "    PandaDFColumn=re.split(', ',PandaDFColumn)\n",
    "    return(PandaDFColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddingDict(ExistingDictionary,LabeledRxnMatrix):\n",
    "    \n",
    "    LabeledRxnMatrix=LabeledRxnMatrix.reset_index(drop=True)\n",
    "    \n",
    "    for rxns in range(len(LabeledRxnMatrix)):\n",
    "        \n",
    "        #Remove any extra spaces\n",
    "        Reactants=[SpaceRemover.sub('',x) for x in LabeledRxnMatrix.Reactants[rxns]]\n",
    "\n",
    "        Products=[SpaceRemover.sub('',x) for x in LabeledRxnMatrix.Products[rxns]]\n",
    "        \n",
    "        #Add values to the Product keys, both the reactants as well as the reactants' as keys to the enzymes\n",
    "        if len(Products)==1:\n",
    "            if LabeledRxnMatrix.Reaction[rxns] in ExistingDictionary[str(Products).strip('[]|\\'')][Reactants[0]]:\n",
    "                pass\n",
    "            else:\n",
    "                ExistingDictionary[str(Products).strip('[]|\\'')][Reactants[0]].append(LabeledRxnMatrix.Reaction[rxns])\n",
    "           \n",
    "        if len(Products)>1:\n",
    "            for cpd in range(len(Products)):\n",
    "                if LabeledRxnMatrix.Reaction[rxns] in ExistingDictionary[str(Products[cpd]).strip('[]|\\'')][Reactants[0]]:\n",
    "                    pass\n",
    "                else:\n",
    "                    ExistingDictionary[str(Products[cpd]).strip('[]|\\'')][Reactants[0]].append(LabeledRxnMatrix.Reaction[rxns])\n",
    "\n",
    "    return(ExistingDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since the data frames got too big, I opted to write out to file then read back in the results in chunks to build the compiled dictionaries of\n",
    "#.. the 13C-labeled metabolic network\n",
    "\n",
    "\n",
    "def BuildDictionaryFromCsv(RoundNum):\n",
    "    #start with blank Dict\n",
    "    RoundDictionary=defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    #Read in the Pandas DF by 10000 row chunks - when I build the loops, the TempPandaDF will be\n",
    "    #a dataframe written to disk as a temporary hold for all the reactions run in a given round\n",
    "    \n",
    "    for chunk in pandas.read_csv('TempPandaDF.csv',sep=',',index_col=False,skip_blank_lines=True,names=['Reaction','Reactants','Products','NewCpds'],chunksize=10000):\n",
    "        #Convert the chunk into a format to be built into dictinoary (i.e. original pandas format)\n",
    "        chunk=ConvertBackForDict(chunk)\n",
    "        #Use the chunk to add into the exisitng dictionary\n",
    "        RoundDictionary=AddingDict(RoundDictionary,chunk)\n",
    "    \n",
    "    #Write out dictionary\n",
    "    output=open('Dictionary_FromRound_{0}.pkl'.format(RoundNum),'wb',-1)\n",
    "    pickle.dump(RoundDictionary,output,protocol=4)\n",
    "    print('Round {0} Done'.format(RoundNum))\n",
    "    \n",
    "    #Remove the TempPandaDF so it doesn't conflict with the next round\n",
    "    os.remove('TempPandaDF.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Run parallel reactions\n",
    "#Note I have these separated by round, one could write a simple loop as well, I liked knowing how long each round took when I was speed-optimizing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 Done\n",
      "CPU times: user 136 ms, sys: 116 ms, total: 252 ms\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Starting from Round 2, use parallel version - note you need a smaller chunk\n",
    "#returning the next round's labeled list, the reaction results are stored as csv to disk\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,2)\n",
    "#Build the dictioanry for a given round, using the TempPandaDF.csv file on disk\n",
    "BuildDictionaryFromCsv(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 Done\n",
      "CPU times: user 196 ms, sys: 72 ms, total: 268 ms\n",
      "Wall time: 611 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,3)\n",
    "BuildDictionaryFromCsv(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4 Done\n",
      "CPU times: user 248 ms, sys: 104 ms, total: 352 ms\n",
      "Wall time: 795 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,4)\n",
    "BuildDictionaryFromCsv(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5 Done\n",
      "CPU times: user 300 ms, sys: 96 ms, total: 396 ms\n",
      "Wall time: 820 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,5)\n",
    "BuildDictionaryFromCsv(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 6 Done\n",
      "CPU times: user 352 ms, sys: 88 ms, total: 440 ms\n",
      "Wall time: 861 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,6)\n",
    "BuildDictionaryFromCsv(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 7 Done\n",
      "CPU times: user 496 ms, sys: 88 ms, total: 584 ms\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,7)\n",
    "BuildDictionaryFromCsv(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 8 Done\n",
      "CPU times: user 956 ms, sys: 96 ms, total: 1.05 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,8)\n",
    "BuildDictionaryFromCsv(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,9)\n",
    "BuildDictionaryFromCsv(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,10)\n",
    "BuildDictionaryFromCsv(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,11)\n",
    "BuildDictionaryFromCsv(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,12)\n",
    "BuildDictionaryFromCsv(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,13)\n",
    "BuildDictionaryFromCsv(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,14)\n",
    "BuildDictionaryFromCsv(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOutRd2(NextRoundCpdList,PipePandaProcess,15)\n",
    "BuildDictionaryFromCsv(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOut(NextRoundCpdList,PipePandaProcess,16)\n",
    "BuildDictionaryFromCsv(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOut(NextRoundCpdList,PipePandaProcess,17)\n",
    "BuildDictionaryFromCsv(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOut(NextRoundCpdList,PipePandaProcess,18)\n",
    "BuildDictionaryFromCsv(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOut(NextRoundCpdList,PipePandaProcess,19)\n",
    "BuildDictionaryFromCsv(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NextRoundCpdList=ParallelRxnBuildWriteOut(NextRoundCpdList,PipePandaProcess,20)\n",
    "BuildDictionaryFromCsv(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keep going if you want, however the path search tended to get overwhelming by 15 rounds, so more calculations may be overkill here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
